{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\"docker kill\" requires at least 1 argument.\n",
      "See 'docker kill --help'.\n",
      "\n",
      "Usage:  docker kill [OPTIONS] CONTAINER [CONTAINER...]\n",
      "\n",
      "Kill one or more running containers\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "docker_name=`docker ps --format '{{.Names}}'`\n",
    "#echo $docker_name\n",
    "docker kill $docker_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tree model_untarred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pygmentize inference.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rfv model_untarred/code/protobuf.tar.gz\n",
    "!(cd model_untarred/code/ && tar -czvf protobuf.tar.gz __init__.py image_pb2.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!(cd model_untarred/ && tar -czvf /tmp/model-resnet-152-inference.tar.gz *)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp /tmp/model-resnet-152-inference.tar.gz s3://ar54/super_models/\n",
    "!aws s3 ls s3://ar54/super_models/   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 ls s3://ar54/super_models/model-resnet-152-inference.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "import mxnet.ndarray as nd\n",
    "from mxnet import nd, autograd, gluon\n",
    "from mxnet.gluon.data.vision import transforms\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "model_arch_path = '/home/ec2-user/SageMaker/resnet-inference-model/model_untarred/resnet-152-symbol.json'\n",
    "model_params_path = '/home/ec2-user/SageMaker/resnet-inference-model/model_untarred/resnet-152-0000.params'\n",
    "\n",
    "# Use GPU if one exists, else use CPU\n",
    "ctx = mx.gpu() if mx.context.num_gpus() else mx.cpu()\n",
    "symbol = mx.sym.load(model_arch_path)\n",
    "\n",
    "#mx.viz.print_summary(symbol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "# The name of our algorithm\n",
    "algorithm_name=chazarey-mxnet-serving-160-gpu-py3\n",
    "\n",
    "account=$(aws sts get-caller-identity --query Account --output text)\n",
    "\n",
    "# Get the region defined in the current configuration (default to us-west-2 if none defined)\n",
    "region=$(aws configure get region)\n",
    "#region=${region:-us-west-2}\n",
    "\n",
    "fullname=\"${account}.dkr.ecr.${region}.amazonaws.com/${algorithm_name}:latest\"\n",
    "\n",
    "# If the repository doesn't exist in ECR, create it.\n",
    "aws ecr describe-repositories --repository-names \"${algorithm_name}\" > /dev/null 2>&1\n",
    "\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "    aws ecr create-repository --repository-name \"${algorithm_name}\" > /dev/null\n",
    "fi\n",
    "\n",
    "# Get the login command from ECR and execute it directly\n",
    "$(aws ecr get-login --region ${region} --no-include-email)\n",
    "\n",
    "# Build the docker image locally with the image name and then push it to ECR\n",
    "# with the full name.\n",
    "\n",
    "#docker build -t chazarey-mxnet-serving:1.6.0-gpu-py3 -f docker/1.6.0/py3/Dockerfile.gpu .\n",
    "\n",
    "docker build -t ${algorithm_name} -f Dockerfile.gpu .\n",
    "\n",
    "docker tag ${algorithm_name} ${fullname}\n",
    "\n",
    "docker push ${fullname}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import sagemaker\n",
    "\n",
    "role = sagemaker.session.get_execution_role()\n",
    "\n",
    "from sagemaker.mxnet import MXNetModel\n",
    "\n",
    "model_data=\"s3://ar54/super_models/model-resnet-152-inference.tar.gz\"\n",
    "\n",
    "model = MXNetModel(\n",
    "    model_data=model_data,\n",
    "    role=role,\n",
    "    image=\"308412838853.dkr.ecr.us-east-2.amazonaws.com/chazarey-mxnet-serving-160-gpu-py3:latest\",\n",
    "    entry_point=\"inference.py\",\n",
    "    py_version='py3',\n",
    "    framework_version='1.6.0'\n",
    ")\n",
    "\n",
    "#predictor = model.deploy(instance_type=\"local_gpu\", initial_instance_count=1)\n",
    "predictor = model.deploy(instance_type=\"local\", initial_instance_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -O /tmp/test.jpg http://www.vision.caltech.edu/Image_Datasets/Caltech256/images/008.bathtub/008_0007.jpg\n",
    "file_name = '/tmp/test.jpg'\n",
    "# test image\n",
    "from IPython.display import Image\n",
    "Image(file_name)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import numpy as np\n",
    "import json\n",
    "from sagemaker.predictor import StringDeserializer\n",
    "import time\n",
    "\n",
    "\n",
    "def numpy_bytes_serializer(data):\n",
    "    f = io.BytesIO()\n",
    "    np.save(f, data)\n",
    "    f.seek(0)\n",
    "    return f.read()\n",
    "\n",
    "predictor.serializer = None\n",
    "predictor.deserializer = StringDeserializer()\n",
    "predictor.accept = None\n",
    "predictor.content_type = None\n",
    "\n",
    "with open(file_name, 'rb') as f:\n",
    "    payload = f.read()\n",
    "    payload = bytearray(payload)\n",
    "\n",
    "for i in range(0, 2):    \n",
    "    response = predictor.predict(payload)            \n",
    "    time.sleep(1)\n",
    "\n",
    "#response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!sudo pip uninstall protobuf\n",
    "#!sudo pip install -U protobuf\n",
    "#!pip install -U protobuf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import numpy as np\n",
    "import json\n",
    "from sagemaker.predictor import StringDeserializer\n",
    "import time\n",
    "import image_pb2 as impb\n",
    "\n",
    "with open('/tmp/test.jpg', 'rb') as f:\n",
    "    payload = f.read()\n",
    "    #payload = bytearray(payload)\n",
    "\n",
    "image_packet = impb.PBImage()\n",
    "image_packet.image_data = payload\n",
    "\n",
    "def numpy_bytes_serializer(data):\n",
    "    f = io.BytesIO()\n",
    "    np.save(f, data)\n",
    "    f.seek(0)\n",
    "    return f.read()\n",
    "\n",
    "predictor.serializer = None\n",
    "predictor.deserializer = StringDeserializer()\n",
    "predictor.accept = None\n",
    "predictor.content_type = 'application/octet-stream'\n",
    "\n",
    "for i in range(0, 2):    \n",
    "    response = predictor.predict(image_packet.SerializeToString())            \n",
    "    time.sleep(1)\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
